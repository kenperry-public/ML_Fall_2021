{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<html>\n",
    "<p style=\"font-size:32px\"><strong>Classical Machine Learning</strong></p>\n",
    "</html>\n",
    "\n",
    "<html>\n",
    "<p style=\"font-size:26px\"><strong>Week 0</strong></p>\n",
    "</html>\n",
    " \n",
    "\n",
    "**Plan**\n",
    "- Setting up your learning and programming environment\n",
    "\n",
    "\n",
    "**Getting started**\n",
    "- [Setting up your ML environment](Setup_NYU.ipynb)\n",
    "    - [Choosing an ML environment](Choosing_an_ML_Environment_NYU.ipynb)\n",
    "- [Quick intro to the tools](Getting_Started.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 1\n",
    "**Plan**\n",
    "- Motivate Machine Learning\n",
    "- Introduce notation used throughout course\n",
    "- Plan for initial lectures\n",
    "    - *What*: Introduce, motivate a model\n",
    "    - *How*:  How to use a model: function signature, code (API)\n",
    "    - *Why*:  Mathematical basis -- enhance understanding and ability to improve results\n",
    "\n",
    "        \n",
    "- [Course Overview](Course_overview_NYU.ipynb)\n",
    "\n",
    "- [Machine Learning: Overview](ML_Overview.ipynb)\n",
    "- [Intro to Classical ML](Intro_Classical_ML.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 2\n",
    "**Plan**\n",
    "- Introduce a model for the Regression task: Linear Regression\n",
    "- Introduce the Recipe for Machine Learning: detailed steps to problem solving\n",
    "\n",
    "- [Our first model: Linear Regression (Overview)](Linear_Regression_Overview.ipynb)\n",
    "- A *process* for Machine Learning\n",
    "    - Go through the methodical, multi-step process\n",
    "        - Quick first pass, followed by Deeper Dives\n",
    "    - This will be a code-heavy notebook !\n",
    "    - Illustrate Pandas, Jupyter, etc\n",
    "    \n",
    "**The Recipe for Machine Learning, illustrated with the Linear Regression model**  \n",
    "- [Recipe for Machine Learning: Overview](Recipe_Overview.ipynb)\n",
    "    - [Linked notebook](Recipe_for_ML.ipynb)\n",
    "\n",
    "- [Linear Regression: Loss Function](Linear_Regression_Loss_Function.ipynb)\n",
    "\n",
    "**Transformations**\n",
    " - [Prepare Data: Intro to Transformations](Prepare_data_Overview.ipynb)\n",
    " \n",
    "**Deeper dives**\n",
    "- Iterative improvement\n",
    "    - [When to stop: Bias and Variance](Bias_and_Variance.ipynb)\n",
    "        - Regularization\n",
    "- [Fine tuning techniques](Fine_tuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 3\n",
    "\n",
    "**Clarification from last week:** [Cross-validation without cheating](Prepare_data_Overview.ipynb#Using-pipelines-to-avoid-cheating-in-cross-validation)\n",
    "\n",
    "**Plan**\n",
    "- Introduce a model for the Classification task: Logistic Regression\n",
    "- How to deal with Categorical (non-numeric) variables\n",
    "    - classification target\n",
    "    - features\n",
    "\n",
    "**Classification intro**\n",
    "- [Classification: Overview](Classification_Overview.ipynb)\n",
    "- [Classification and Categorical Variables](Classification_Notebook_Overview.ipynb)\n",
    "    - [linked notebook](Classification_and_Non_Numerical_Data.ipynb)\n",
    "\n",
    "**Classification, continued**\n",
    "- [Multinomial Classification](Multinomial_Classification.ipynb)\n",
    "- [Classification Loss Function](Classification_Loss_Function.ipynb)\n",
    "\n",
    "**Deeper dives**\n",
    "- [Log odds](Classification_Log_Odds.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 4\n",
    "\n",
    "Good news\n",
    "- You now know two main tasks in Supervised Learning\n",
    "    - Regression, Classification\n",
    "- You now know how to use virtually every model in `sklearn`\n",
    "    - Consistent API\n",
    "        - `fit`, `transform`, `predict`\n",
    "- You survived the \"sprint\" to get you up and running with ML\n",
    "- You know the *mechanical process* to implement transformations: Pipelines\n",
    "    \n",
    "**Plan**\n",
    "- Classsification and Categorical variables wrapup\n",
    "    - Baseline models: a baseline model for classification\n",
    "    - OHE and Linear Regression: The Dummy Variable Trap\n",
    "- Error Analysis\n",
    "    - We explain Error Analysis for the Classification Task, with a detailed example\n",
    "    - How Training Loss can be improved\n",
    "- Transformations, continued\n",
    "    - One of the most important parts of the Recipe: transforming raw data into something that tells a story\n",
    "- Loss functions\n",
    "    - We look at the mathematical logic behind loss functions\n",
    "\n",
    "\n",
    "**Classsification and Categorical variables wrapup**\n",
    "- [Dummy variable trap](Dummy_Variable_Trap.ipynb)\n",
    "- [Baseline model for Classification](Classification_Baseline_Model.ipynb)\n",
    "\n",
    "\n",
    "**Error Analysis**\n",
    "- [Error Analysis](Error_Analysis_Overview.ipynb)\n",
    "    - [linked notebook](Error_Analysis.ipynb)\n",
    "        - Summary statistics\n",
    "        - Conditional statistics\n",
    "    - [Worked example](Error_Analysis_MNIST.ipynb)\n",
    "\n",
    "- [Loss Analysis: Using training loss to improve models](Training_Loss.ipynb)\n",
    " \n",
    "**Transformations, continued**\n",
    "- [Transformations Overview](Transformations_Overview.ipynb)\n",
    "\n",
    "**Loss function**\n",
    "- [Loss functions: the math](Loss_functions.ipynb)\n",
    "    - Maximum likelihood\n",
    "    - Preview: custom loss functions and Deep Learning\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 5\n",
    "\n",
    "**Plan**\n",
    "- More models: Decision Trees, Naive Bayes\n",
    "    - Different flavor: more procedural, less mathematical\n",
    "    - Decision Trees: a model with *non-linear* boundaries\n",
    "- Ensembles\n",
    "    - Bagging and Boosting\n",
    "    - Random Forests\n",
    "- Naive Bayes: a simple but effective model\n",
    "\n",
    "**Last week's topics, more in depth**\n",
    "- More on [Imbalanced data](Imbalanced_Data.ipynb)\n",
    "- [Entropy, Cross Entropy, and KL Divergence](Entropy_Cross_Entropy_KL_Divergence.ipynb)\n",
    "\n",
    "**Decision Trees, Ensembles**\n",
    "\n",
    "- [Decision Trees: Overview](Decision_Trees_Overview.ipynb)\n",
    "- [Decision Trees](Decision_Trees_Notebook_Overview.ipynb)\n",
    "    - [linked notebook](Decision_Trees.ipynb)\n",
    "- [Trees, Forests, Ensembles](Ensembles.ipynb)\n",
    "\n",
    "**Naive Bayes**\n",
    "- [Naive Bayes](Naive_Bayes.ipynb)\n",
    "\n",
    "**Gradient Descent** (start)\n",
    "- [Gradient Descent](Gradient_Descent.ipynb)\n",
    "\n",
    "**Deeper Dives**\n",
    "- [Feature importance](Feature_Importance.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 6    \n",
    "**Plan**\n",
    "\n",
    "- Gradient Descent: our tools for solving optimization problems (continued)\n",
    "- Unsupervised Learning: feature vectors without labels/targets (start)\n",
    "    - Dimensionality reduction (useful for Midterm Project)\n",
    "- Support Vector Classifiers: a classifier with an interesting twist (start)\n",
    "\n",
    "**Gradient Descent** (continued from last week)\n",
    "- [Gradient Descent](Gradient_Descent.ipynb)\n",
    "\n",
    "**Unsupervised Learning: PCA (start)**\n",
    "- [Unsupervised Learning: Overview](Unsupervised_Overview.ipynb)\n",
    "- [PCA Notebook Overview](Unsupervised_Notebook_Overview.ipynb)\n",
    "    - [linked notebook](Unsupervised.ipynb)\n",
    "  \n",
    "**Support Vector Classifiers (start)**\n",
    "- [Support Vector Machines: Overview](SVM_Overview.ipynb)\n",
    "- [SVC Loss function](SVM_Hinge_Loss.ipynb)\n",
    "- [SVC: Large Margin Classification](SVM_Large_Margin.ipynb)    \n",
    "        \n",
    "**Deeper Dives**\n",
    "- [SVC Loss function derivation](SVM_Derivation.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 7\n",
    "\n",
    "**Plan**\n",
    "- Support Vector Classifiers: a classifier with an interesting twist (continued)  \n",
    "    - Support Vector Machines: Kernel Transformations\n",
    " \n",
    "- Unsupervised Learning: feature vectors without labels/targets (continued)\n",
    "    - PCA in Finance\n",
    "        - Yield Curve movements\n",
    "        - Equity Index member returns\n",
    "    - Netflix challenge\n",
    "        - non-standard matrix factorization\n",
    "        - Interesting Loss function\n",
    "        - A bridge to Deep Learning\n",
    "        \n",
    "- Interpretation: understanding models\n",
    "\n",
    "**Imbalanced data (clarification)**\n",
    "- [Data Augmentation: side-effects](Imbalanced_Data.ipynb#Issues-with-augmenting-the-training-examples)\n",
    "\n",
    "**Support Vector Classifiers (continued)**\n",
    "- [SVM: Kernel Transformations](SVM_Kernel_Functions.ipynb)\n",
    "- [SVM Wrapup](SVM_Coda.ipynb)\n",
    "\n",
    "**Unsupervised Learning (continued)**\n",
    "- [Interpreting the Components](PCA_Interpretation.ipynb)\n",
    "- [PCA in Finance](PCA_Yield_Curve_Intro.ipynb)\n",
    "    - [linked notebook](Unsupervised.ipynb)\n",
    "- [Pseudo Matrix Factorization](Pseudo_Matrix_Factorization.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "**Interpretation**\n",
    "- [Interpretation: Linear Models](Linear_Model_Interpretation.ipynb)\n",
    "  \n",
    "Deeper dives\n",
    "- [Other matrix factorization methods](Unsupervised_Other_Factorizations.ipynb)\n",
    "- [Missing data: clever ways to impute values](Missing_Data.ipynb)\n",
    "\n",
    "## Deep Learning: Headstart\n",
    "\n",
    "### Week 1 Introduction to Neural Networks and Deep Learning\n",
    "\n",
    "**Plan**\n",
    "\n",
    "Deep Learning/Neural networks\n",
    "\n",
    "- [Set up your Tensorflow environment](Tensorflow_setup.ipynb)\n",
    "- [Neural Networks Overview](Neural_Networks_Overview.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<html>\n",
    "<p style=\"font-size:32px\"><strong>Deep Learning</strong></p>\n",
    "</html>\n",
    "\n",
    "# Week 1 Introduction to Neural Networks and Deep Learning\n",
    "\n",
    "**Plan**\n",
    "\n",
    "- \n",
    "Continue our introduction to Neural Networsk/Deep Learning\n",
    "\n",
    "- Neural network: practical\n",
    "- Neural network theory: continued\n",
    "\n",
    "**Neural network: overview**\n",
    "- [Neural Networks Overview \\(continued\\)](Neural_Networks_Overview.ipynb#Final-layer:-Regression/Classification)\n",
    "\n",
    "**Neural network: practical**\n",
    "- Coding Neural Networks: Tensorflow, Keras\n",
    "    - [Intro to Keras](Tensorflow_Keras.ipynb)\n",
    "\n",
    "- Practical Colab\n",
    "<!--- The Colab notebook imports some modules; make sure they are in the repo --->\n",
    "<!--- #include (neural_net_helper.py) --->\n",
    "<!--- The Colab notebook imports some modules; make sure they are in the repo --->\n",
    "<!--- #include (Colab_practical.ipynb)) --->\n",
    "   - **Colab**: [Practical Colab Notebook from github](https://colab.research.google.com/github/kenperry-public/ML_Fall_2021/blob/master/Colab_practical.ipynb)\n",
    " \n",
    "**Neural network theory**\n",
    "- [A neural network is a Universal Function Approximator](Universal_Function_Approximator.ipynb)\n",
    "   \n",
    "**Deeper Dives**\n",
    "- [Keras, from past to present](Tensorflow_Keras_Archaeology.ipynb)\n",
    "- [History/Computation Graphs: Tensorflow version 1](DNN_TensorFlow_Using_TF_version_1.ipynb)\n",
    "- [Raw_TensorFlow example Notebook from github](https://colab.research.google.com/github/kenperry-public/ML_Spring_2020/blob/master/Raw_TensorFlow.ipynb) (**Colab**)\n",
    "- [Computation Graphs](Computation_Graphs.ipynb)\n",
    "\n",
    "\n",
    "## Convolutional Neural Networks \n",
    "\n",
    "**Convolutional Neural Networks (CNN)**\n",
    "- [Introduction to CNN](Intro_to_CNN.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 2 Convolutional Neural Networks\n",
    "\n",
    "**Plan**\n",
    "- Continue our exploration of the Convolutional Neural Network layer type\n",
    "- Introduce the topic of Training Neural Networks\n",
    "\n",
    "\n",
    "**Convolutional Neural Networks (CNN)**\n",
    "- [CNN: multiple input/output features](CNN_Overview.ipynb)\n",
    "- [CNN: Space and Time](CNN_Space_and_Time.ipynb)\n",
    "    - [CNN example from github](https://colab.research.google.com/github/kenperry-public/ML_Fall_2021/blob/master/CNN_demo.ipynb) (**Colab**) \n",
    "    - [CNN example from github](CNN_demo.ipynb) (**local machine**) \n",
    "\n",
    "**Training Neural Networks (introduction)**\n",
    "- [Training Neural Networks - Back propagation](Training_Neural_Network_Backprop.ipynb)\n",
    "\n",
    "**Deeper dives**\n",
    "- [Convolution as Matrix Multiplication](CNN_Convolution_as_Matrix_Multiplication.ipynb)\n",
    "\n",
    "## Recurrent Neural Networks\n",
    "\n",
    "- [Introduction to Recurrent Neural Network (RNN)](Intro_to_RNN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 3 Recurrent Neural Networks\n",
    "\n",
    "**Plan**\n",
    "- Introduce a new layer type: Recurrent layers\n",
    "    - Part of our \"sprint\": final layer type\n",
    "    - Will revisit more theoretical issues in subsequent lectures\n",
    "    \n",
    "- [Introduction to Recurrent Neural Network (RNN) -- continued](Intro_to_RNN.ipynb#Recurrent-Neural-Network-(RNN)-layer)\n",
    "- [Recurrent Neural Network Overview](RNN_Overview.ipynb)\n",
    "    - [LSTM_text_generation from github](https://colab.research.google.com/github/kenperry-public/ML_Fall_2021/blob/master/Keras_examples_LSTM_text_generation.ipynb) (**Colab**)\n",
    "    - [LSTM_text_generation from github](Keras_examples_LSTM_text_generation.ipynb) (**local machine**)\n",
    "\n",
    "**Review of layer types**\n",
    "- [What layer type to choose](Neural_Network_Layer_Review.ipynb)\n",
    "\n",
    "Sprint is over ! We have covered the basic layer types; time for you to learn by experimenting.\n",
    "\n",
    "In the remaining weeks, we will learn advanced concepts, motivated by the question\n",
    ">What took so long ?\n",
    "\n",
    "**Training Neural Networks: the fine details**\n",
    "- [Training Neural Networks: fine details](Training_Neural_Networks_Overview.ipynb)\n",
    "\n",
    "\n",
    "**Deeper dives**\n",
    "- [RNN: How to deal with long sequences](RNN_Long_Sequences.ipynb)\n",
    "- [Tensors: Matrix gradients](Matrix_Gradient.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 4 Advanced Recurrent Architectures\n",
    "\n",
    "**Plan**\n",
    "\n",
    "\n",
    "We wrap up the \"What took so long ?\" discussion (i.e., the nitty-gritty details of training a neural network_\n",
    "\n",
    "The discussion reveals problems that arise in training neural networks and motivates the introduction of new layer types that address the issues.\n",
    "\n",
    "We continue the discussion of problems that are specific to RNNs.\n",
    "\n",
    "The \"vanilla\" Recurrent Neural Network (RNN) layer we learned is very much exposed to the problem of vanishing/exploding gradients.\n",
    "\n",
    "We will review the issue and demonstrate a related layer type (the LSTM) designed to mitigate the problem.\n",
    "\n",
    "**A state of the art Generative model** (meant to show it last week)\n",
    "- [A state of the art Generative model](RNN_in_action.ipynb#Generative-text:-state-of-the-art)\n",
    "\n",
    "**Training neural networks (continued)**\n",
    "- [Training Neural Networks:Initializing weights (continued)](Training_Neural_Networks_Scaling_and_Initialization.ipynb#Initialization)\n",
    "\n",
    "- [Training Neural Networks: Improving trainability](Training_Neural_Networks_Overview.ipynb#Improving-trainability)\n",
    "\n",
    "**RNN: Issues**\n",
    "- [Gradients of an RNN](RNN_Gradients.ipynb)\n",
    "- [RNN: Gradients that Vanish/Explode](RNN_Vanishing_and_exploding_gradients.ipynb)\n",
    "- [Residual connections](RNN_Residual_Networks.ipynb)\n",
    "\n",
    "**LSTM: An improved RNN**\n",
    "- [Neural Programming](Neural_Programming.ipynb)\n",
    "- [Introduction to the LSTM](Intro_to_LSTM.ipynb)\n",
    "- [LSTM Overview](LSTM_Overview.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 5 Transfer Learning; Natural Language Processing\n",
    "\n",
    "**Plan**\n",
    "\n",
    "We  present an extremely useful trick for leveraging the hard work that others have done.\n",
    "\n",
    "Next we try to develop intuition for what is occurring within a Neural Network.\n",
    "\n",
    "We will also introduce a powerful mechanism called Attention that has recently become quite popular and\n",
    "important.\n",
    "\n",
    "**Plan**\n",
    "We will make an initial pass on the topic of learning from text: Natural Language Processing.\n",
    "\n",
    "- [Transfer Learning](Transfer_Learning.ipynb)\n",
    "\n",
    "     - [Transfer Learning example from github](https://colab.research.google.com/github/kenperry-public/ML_Fall_2021/blob/master/TransferLearning_demo.ipynb) (**Colab**)\n",
    "     - [Transfer Learning example from github](TransferLearning_demo.ipynb) (**local machine**)\n",
    "\n",
    "     - [Utility notebook](Dogs_and_Cats_reformat.ipynb)\n",
    "         - Takes the *very large* raw data (from Kaggle) used in the Transfer Learning example\n",
    "         - Creates a much smaller subset, using a different directory structure\n",
    "         - The above notebook uses this reorganized, smaller subset\n",
    "\n",
    "    \n",
    "**Interpretation**\n",
    "- [Interpretation: preview](Interpretation_preview.ipynb)\n",
    "\n",
    "**Learning from text: Deep Learning for Natural Language Processing (NLP)**\n",
    "- [Natural Language Processing Overview](NLP_Overview.ipynb)\n",
    "    - [NLP from github (Colab)](https://colab.research.google.com/github/kenperry-public/ML_Fall_2021/blob/master/Keras_examples_imdb_cnn.ipynb)\n",
    "    - [NLP from github (local machine)](Keras_examples_imdb_cnn.ipynb)\n",
    "\n",
    "**Further reading**\n",
    "- [Sebastian Ruder: Transfer Learning](https://ruder.io/transfer-learning/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 6 Attention\n",
    "\n",
    "**Attention**\n",
    "- [Attention](Intro_to_Attention.ipynb)\n",
    "- [Implementing Attention](Attention_Lookup.ipynb)\n",
    "\n",
    "**Further reading**\n",
    "- Attention\n",
    "    - [Neural Machine Translation by Jointly Learning To Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)\n",
    "    - [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 7 Advanced Topics\n",
    "\n",
    "**Continued from last week**\n",
    "\n",
    "**Attention**\n",
    "- [Attention](Intro_to_Attention.ipynb)\n",
    "- [Implementing Attention](Attention_Lookup.ipynb)\n",
    "\n",
    "**What is a Neural Network really doing ? Interpretation**\n",
    "- [Introduction to Interpretation of Deep Learning](Intro_to_Interpretation_of_DL.ipynb)\n",
    "- [Interpretation: Simple Methods](Interpretation_of_DL_Simple.ipynb)\n",
    "- [Interpretation: Saliency Maps](Interpretation_of_DL_Deconv.ipynb)\n",
    "- [Interpretation: Gradient Ascent](Interpretation_of_DL_Gradient_Ascent.ipynb)\n",
    "- [Adversarial Examples](Adversarial_Examples.ipynb)\n",
    "\n",
    "**Wrapping up**\n",
    "- [Final thoughts](Deep_Learning_Coda.ipynb)\n",
    "\n",
    "**Deeper Dives**\n",
    "- [Interpretation using Principal Components](Interpretation_of_DL_Simple_PCA.ipynb)\n",
    "- [Interpretation: Attention](Interpretation_of_DL_Attention.ipynb)\n",
    "\n",
    "**Further reading**\n",
    "- [Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignments\n",
    "\n",
    "Your assignments should follow the [Assignment Guidelines](assignments/Assignment_Guidelines.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression\n",
    "- Assignment notebook: [Using Machine Learning for Hedging](assignments/Regression%20task/Using_Machine_Learning_for_Hedging.ipynb)\n",
    "- Data\n",
    "    - There is an archive file containing the data\n",
    "    - You can find it\n",
    "        - Under the course page: Content --> Data --> Assignments --> Regression task\n",
    "        - You won't be able to view the file in the browser, but you **will** be able to Download it\n",
    "    - You should unzip this archive into the *the same directory* as the assignment notebook\n",
    "    - The end result is that the directory should contain\n",
    "        - The assignment notebook and a helper file\n",
    "        - A directory named `Data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "- Assignment notebook: [Ships in satellite images](assignments/Classification%20task/Ships_in_satellite_images.ipynb#)\n",
    "- Data\n",
    "    - There is an archive file containing the data\n",
    "    - You can find it\n",
    "        - Under the course page: Content --> Data --> Assignments --> Classification task\n",
    "        - You won't be able to view the file in the browser, but you **will** be able to Download it\n",
    "    - You should unzip this archive into the *the same directory* as the assignment notebook\n",
    "    - The end result is that the directory should contain\n",
    "        - The assignment notebook and a helper file\n",
    "        - A directory named `Data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Midterm Project: Bankruptcy One Year Ahead\n",
    "- Assignment notebook [Bankruptcy One Year Ahead](assignments/bankruptcy_one_yr/Bankruptcy_oya.ipynb)\n",
    "- Data\n",
    "    - There is an archive file containing the data\n",
    "    - You can find it\n",
    "        - Under the course page: Content --> Data --> Assignments --> Bankruptcy One Year Ahead\n",
    "        - You won't be able to view the file in the browser, but you **will** be able to Download it\n",
    "    - You should unzip this archive into the *the same directory* as the assignment notebook\n",
    "    - The end result is that the directory should contain\n",
    "        - The assignment notebook and a helper file\n",
    "        - A directory named `Data`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras practice\n",
    "- Assignment notebook [Ships in satellite images: Neural Network](assignments/keras_intro/Ships_in_satellite_images_P1.ipynb)\n",
    "- Data (same as for the Classification assignment)\n",
    "    - please repeat the directions given in that assignment for obtaining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolutional Neural Networks (CNN)\n",
    "- Assignment notebook [Ships in satellite images: Neural Network](assignments/CNN_intro/Ships_in_satellite_images_P2.ipynb)\n",
    "- Data (same as for the Classification assignment)\n",
    "    - please repeat the directions given in that assignment for obtaining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stock prediction\n",
    "\n",
    " - Assignment notebooks:\n",
    "    - [Stock prediction](assignments/stock_prediction/Final_project_StockPrediction.ipynb)\n",
    "    - [Submission guidelines](assignments/stock_prediction/Final_project.ipynb)\n",
    "   \n",
    " - Data\n",
    "    - There is an archive file containing the data\n",
    "    - You can find it\n",
    "        - Under the course page: Content --> Data --> Assignments --> Stock Prediction\n",
    "        - You won't be able to view the file in the browser, but you **will** be able to Download it\n",
    "    - You should unzip this archive into the *the same directory* as the assignment notebook\n",
    "    - The end result is that the directory should contain\n",
    "        - The assignment notebook, submission guidelines notebook\n",
    "        - A directory named `Data/train`\n",
    "\n",
    "        - The assignment notebook and a helper file\n",
    "        - A directory named `Data`\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
