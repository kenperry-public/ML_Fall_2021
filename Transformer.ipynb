{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN) layer\n",
    "\n",
    "**Review**\n",
    "\n",
    "With a sequence $\\x^\\ip$ as input, and a sequence $\\y$ as a potential output,  the questions arises:\n",
    "- How does an RNN produce $\\y_\\tp$, the $t^{th}$ output ?\n",
    "\n",
    "Some choices\n",
    "- Predict $\\y_\\tp$ as a direct function of the prefix of $\\x$ of length $\\tt$: \n",
    "$$\\pr{\\y_\\tp | \\x_{(1)} \\dots \\x_\\tp} $$\n",
    "\n",
    "- Uses a \"latent state\" that is updated with each element of the sequence, then predict the output\n",
    "\n",
    "$$\n",
    "\\begin{array}[lll] \\\\\n",
    "\\pr{\\h_\\tp | \\x_\\tp, \\h_{(\\tt-1)} } & \\text{latent variable } \\h_\\tp \\text{encodes } [ \\x_{(1)} \\dots \\x_\\tp ]\\\\\n",
    "\\pr{\\y_\\tp | \\h_\\tp }              & \\text{prediction contingent on latent variable} \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In our first encounter with the RNN, we made the choice to use the \"latent state\" approach.\n",
    "\n",
    "Doing so enabled us to picture an RNN as a loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>RNN</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/RNN_loop.jpg\" width=1000></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "During  iteration $t$ of the loop\n",
    "- We consume input $\\x_\\tp$\n",
    "- Produce output $\\y_\\tp$ (which we will assume is the latent state: $\\y_\\tp = \\h_\\tp$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also indicated that we could \"unroll\" the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>RNN unrolled</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/RNN_layer_API_many_to_many.jpg\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformer layer\n",
    "\n",
    "What would have happened if, rather than using the latent state approach, we choose the alternative:\n",
    "- Predict $\\y_\\tp$ as a direct function of the prefix of $\\x$ of length $\\tt$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the picture would look similar to the \"unrolled\" loop:\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Transformer layer</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Transformer_1.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compared to the unrolled RNN, the Transformer, the computation at step $t$\n",
    "- Has **no** data (e.g., $\\h_\\tp)$ passing from the computation between time steps (from $(t-1)$, to $(t+1)$)\n",
    "- Takes a **sequence** $\\x_{(1..t)}$ as input\n",
    "    - Because $\\y_\\tp$ is computed as a *direct* function of the prefix $\\x_{(1..t)}$ rather than recursively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In some instances, we may even allow the Transformer to \"see\" the *entire* input (not just a prefix) at each step $t$\n",
    "- The Encoder of an Encoder-Decoder architecture\n",
    "    - Context Sensitive Encoding\n",
    "        - Encode based on *entire* input\n",
    "        - Bi-directional RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Transformer layer</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Transformer_2.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Transformer uses *self-attention*\n",
    "- To influence which elements of $\\x_{(1 \\ldots \\, t)}$ to attend/focus to\n",
    "\n",
    "Looking inside the circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Transformer Layer (Encoder)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Transformer_Encoder.png\" width=70%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And there are cases where we *must not* allow the Transformer to \"see\" the *entire* input\n",
    "- The Decoder of an Encoder-Decoder architecture\n",
    "    - Teacher forcing: the input of step $(t+1)$ is $\\y_\\tp$, the output of step $t$\n",
    "    - Can't look ahead to something that has not yet been created !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For those cases where look-ahead is not allowed, the Transformer using **masking**\n",
    "- Hide the suffix $\\y_{(t+1 \\ldots \\, t)}$ from the attention layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Transformer Layer (Decoder)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Transformer_Decoder.png\" width=70%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You will notice two Attention layers\n",
    "- **Masked** Self Attention (on $\\y$)\n",
    "    - Allows the layer to focus on previous outputs\n",
    "        - Masked to prevent look-ahead to $\\y_{(t')}$ for $t' > t$\n",
    "- Encoder-Decoder Attention (on $\\bar\\h_\\tp$)\n",
    "    - Allows the Decoder to attend to the entire output sequence of the Encoder\n",
    "    \n",
    "So this layer attends to\n",
    "- previously generated Decoder layer outputs\n",
    "- the \"relevant\" part of the Encoder output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Transformer Layer (Encoder/Decoder)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Transformer_Encoder_Decoder.png\" width=70%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Transformer architecture just stacks $N$ Transformer layers.\n",
    "\n",
    "$N = 6$ was the choice of the original paper.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Stacked Transformer Layers (Encoder/Decoder)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Transformer_Encoder_Decoder_multi.png\" width=70%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Advantages of a Transformer compared to an RNN\n",
    "- Time: All steps computed in parallel\n",
    "    - $O(1)$ sequential steps versus $O(T)$\n",
    "- Fewer operations: faster training\n",
    "    - $O( T^2 * d )$ versus $O(T * d^2)$, where $d$ is length of a single input element\n",
    "        - e.g., $\\x_\\tp$ replaced by an embedding of dimension $d$\n",
    "    - Transformer has fewer operations when $T \\lt d$\n",
    "- Similar number of parameters \n",
    "    - When $T < \\sqrt{d}$: Self attention has about the same number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that, because of TBTT, T is the length of a *chunk* rather than the full input length\n",
    "- Typical $T = 64, d \\ge 256$\n",
    "\n",
    "So under the special case (that applies to sequences) that chunk length is short relative to representation size,\n",
    "it is not \"crazy\" to perform all elements of $\\x$ with separate FC's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Detailed comparison of architectures\n",
    "\n",
    "| Type | Parameters  | Operations\\;\\; | Path length |\n",
    "|------|------       |------      |------       |\n",
    "|  CNN | $k * d^2$   | $T * k * d^2$ | $T$ |\n",
    "| RNN  | $d^2$       | $T * d^2$     | $T$ |\n",
    "| Self-attention | $T^2 *d $ | $T^2 *d$ | 1 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's the details of the math        \n",
    "\n",
    "Attention involves a dot product (of vectors of length $d$)\n",
    "- Each input matched against all others: $T * T$\n",
    "- So $T^2 *d$ operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "RNN\n",
    "- $T$ sequential steps\n",
    "- Each step evaluates\n",
    "    $$\n",
    "\\h_\\tp  =  \\phi(\\W_{xh}\\x_\\tp  + \\W_{hh}\\h_{(t-1)}  + \\b_h) \n",
    "$$\n",
    "- $\\h_\\tp$ has multiple elements, assume $|| \\h || = O(d)$\n",
    "    - Computing updated hidden state element $j$ (i.e., $\\h_{\\tp, j}$) involves dot product of vectors of length $d$ (size of $\\x_\\tp)$\n",
    "    - $d$ multiplications per element of $\\h$, times $O(d)$ elements of $\\h$ is $O(d^2)$ per step\n",
    "    - So $T * d^2$ operations\n",
    "    \n",
    "- $\\W_{hh}$ matrix: $d^2$ parameters\n",
    "  - $ | \\h | = d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "CNN\n",
    "- path length $T$ \n",
    "    - each kernel multiplication connects only $k$ elements of $\\x$\n",
    "    - have to stack CNN's to get function of all $T$ elements\n",
    "        - can reduce to $\\log(T)$ with tree structure\n",
    "- Parameters\n",
    "    - kernel size $k$\n",
    "    - number of input channels = number of output channels = $d$\n",
    "    - $k * d^2$ parameters\n",
    "    \n",
    "- Operations\n",
    "    - for a single output channel: $k$ per input channel\n",
    "        - There are $d$ input channels, so $k *d$ for each dot product of *one* output channel\n",
    "        - There are $d$ output channels, so $k * d^2$ per time step\n",
    "    - $T$ time steps so $T * k * d^2$ number of operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "RNN\n",
    "- $\\W_{hh}$ matrix: $d^2$ parameters\n",
    "  - $ | \\h | = d$\n",
    "- $T * d^2$ operations (for entire sequence)\n",
    "- path length $T$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To summarize\n",
    "- for short chunk/sequence length, relative to size of hidden state\n",
    "    - $|x| \\lt 64$ typically; $d \\approx 256$\n",
    "- Transformer/self attention is comparable in terms of number of parameters\n",
    "\n",
    "So under the special case (that applies to sequences) that chunk length is short relative to representation size,\n",
    "it is not \"crazy\" to perform all elements of $\\x$ with separate FC's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A free lunch ? Almost !\n",
    "\n",
    "Transformers offer the possibility of great improvements in training speed\n",
    "- Parallelism\n",
    "- Fewer operations\n",
    "    \n",
    "Sounds too good to be true.  Is there such a thing as a free lunch ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Almost\n",
    "- RNN can handle sequences of arbitrary length ($T$ unbounded)\n",
    "- Transformer has a fixed number of parallel units, which limits the length of sequences\n",
    "\n",
    "But, in practice: RNN uses *Truncated* Back Propagation Through Time\n",
    "- So the maximum distance between input sequence elements is bounded by $k$, the truncation length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
